## 페이지 바꾸면서 파싱, tbody로
import pandas as pd


num = 0

dfs = pd.DataFrame()
def crawl_ipos(num):
    global dfs
    url = 'http://www.38.co.kr/html/fund/index.htm?o=nw&page='+str(num)
    #html = requests.get(url)
    # soup.prettify()
    df = pd.read_html(url)[14][1:21]
    #df.to_excel('C:\\ipos.xlsx')
    dfs = pd.concat([dfs,df])
    #print(dfs)

# 31페이지에 2012년
for i in range(1,32):
    crawl_ipos(i)
    i = i+1
print(dfs)
dfs.to_excel('C:\\ipos.xlsx')
